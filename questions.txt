Questions To Answer

* On average, how many successful requests can ab complete to /token in 8 
seconds with various power-of-two concurrency levels between 1 and 256?

`ab -t 8 -c <number> https://e1uvvl93l6.execute-api.us-west-2.amazonaws.com/prod/`

Concurrency |   1 |   2 |    4 |    8 |   16 |    32 |    64 |   128 |   256
------------+-----+-----+------+------+------+-------+-------+-------+-------
# Requests  |  51 | 105 |  207 |  413 |  814 |  1623 |  3277 |  6480 | 12368

* Using data you’ve collected, describe how this service’s performance compares 
to that of your static webpage from Project 0 (remeasure those results if 
necessary).

`ab -t 10 -c <number> https://ashleyswang.github.io/cs291a-boe/project-0/`

Concurrency |   1 |   2 |    4 |    8 |   16 |    32 |    64 |   128 |   256
------------+-----+-----+------+------+------+-------+-------+-------+-------
# Requests  | 470 | 996 | 1958 | 4161 | 8067 | 16606 | 22456 | 22966 | 23604

`ab -t 10 -c <number> https://e1uvvl93l6.execute-api.us-west-2.amazonaws.com/prod/`

Concurrency |   1 |   2 |    4 |    8 |   16 |    32 |    64 |   128 |   256
------------+-----+-----+------+------+------+-------+-------+-------+-------
# Requests  |  63 | 131 |  264 |  515 | 1035 |  2056 |  4142 |  8220 | 15849

Comparing the number of requests completed for 10 seconds, we can see that ab 
can complete about 7.5x more requests for project 0 than for project 1 for 
lower concurrency levels. For c=1, p0 completes 470 requests whereas p1 
completes 63. This scale is consistent until concurrency level 256. 

At concurrency level 256, we notice that p0 does not double its number of 
completed requests from 128 (22966 -> 23604), but p1 still scales linearly with 
128 to 256 concurrency level completing 8220 -> 15849 requests. This suggests 
that maybe the bottleneck is elsewhere for the AWS servers since they might 
have more overall processing power to handle more number of requests at a time. 

* What do you suspect accounts for the difference in performance between GitHub 
pages and your AWS Lambda web service?

Since Github hosts only static webpages, it most likely uses an HTTP server to 
retrieve its contents and respond to requests. Since HTTP servers are optimized 
for handling concurrent HTTP requests, we see that our P0 website can handle
much more traffic responding to almost 23000 requests in 10 seconds for 
concurrency level 128. 

By contrast AWS Lamda most likely utilizes both an application server and an
HTTP server to generate its contents. Application servers are much slower since
they were built to be more versatile and allow for dynamic content generated by 
high-level language that are not optimized for speed. For our P1 website we use 
Ruby to handle requests which is relatively slow and therefore we respond to a 
much smaller number of requests in the same time with the same concurrency 
level. We can additionally attribute latency to the communication time between
the HTTP server and the application server since the Ruby script must be 
retrieved and ran by the server. 